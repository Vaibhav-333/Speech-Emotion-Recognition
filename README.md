Designed a model that classifies emotions (like happy, sad, angry) from human speech using audio signal processing and machine learning.
â€¢ Extracted MFCC and other acoustic features from voice samples, trained a neural network, and evaluated it using accuracy, confusion matrix, and waveform visualizations
